#!/usr/bin/env python3
"""
å›¾ç‰‡tokenæ¶ˆè€—åˆ†æå·¥å…·

ç”¨æ³•ï¼š
    python analyze_tokens.py <folder_path>

åŠŸèƒ½ï¼š
- åˆ†ææ–‡ä»¶å¤¹ä¸­æ‰€æœ‰å›¾ç‰‡çš„å°ºå¯¸å’Œé¢„ä¼°tokenæ¶ˆè€—
- æ¯”è¾ƒå‹ç¼©å‰åçš„tokenå·®å¼‚
- æä¾›ä¼˜åŒ–å»ºè®®
"""

import os
import sys
from pathlib import Path
from PIL import Image
import json


def estimate_tokens(width: int, height: int) -> int:
    """ä¼°ç®—Vision APIçš„tokenæ¶ˆè€—"""
    # è°ƒæ•´åˆ°2048x2048ä»¥å†…
    max_dim = max(width, height)
    if max_dim > 2048:
        scale = 2048 / max_dim
        width = int(width * scale)
        height = int(height * scale)
    
    # è®¡ç®—éœ€è¦å¤šå°‘ä¸ª512x512çš„å—
    tiles_width = (width + 511) // 512
    tiles_height = (height + 511) // 512
    total_tiles = tiles_width * tiles_height
    
    # æ¯ä¸ªtileå¤§çº¦170 tokensï¼ŒåŠ ä¸Šå›ºå®š85 tokens
    return total_tiles * 170 + 85


def analyze_image(image_path: str) -> dict:
    """åˆ†æå•å¼ å›¾ç‰‡"""
    try:
        with Image.open(image_path) as img:
            width, height = img.size
            file_size = os.path.getsize(image_path)
            
            # åŸå§‹tokenæ¶ˆè€—
            original_tokens = estimate_tokens(width, height)
            
            # ä¸åŒå‹ç¼©è®¾ç½®ä¸‹çš„tokenæ¶ˆè€—
            compressed_scenarios = []
            for max_size in [512, 768, 1024, 1280]:
                if max(width, height) > max_size:
                    if width > height:
                        new_width = max_size
                        new_height = int(height * max_size / width)
                    else:
                        new_height = max_size
                        new_width = int(width * max_size / height)
                else:
                    new_width, new_height = width, height
                
                compressed_tokens = estimate_tokens(new_width, new_height)
                compression_ratio = compressed_tokens / original_tokens if original_tokens > 0 else 1
                
                compressed_scenarios.append({
                    "max_size": max_size,
                    "new_dimensions": f"{new_width}x{new_height}",
                    "tokens": compressed_tokens,
                    "compression_ratio": compression_ratio,
                    "token_savings": original_tokens - compressed_tokens
                })
            
            return {
                "path": image_path,
                "original_dimensions": f"{width}x{height}",
                "file_size_kb": file_size / 1024,
                "original_tokens": original_tokens,
                "compressed_scenarios": compressed_scenarios,
                "success": True
            }
    except Exception as e:
        return {
            "path": image_path,
            "error": str(e),
            "success": False
        }


def main():
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python analyze_tokens.py <folder_path>")
        sys.exit(1)
    
    folder_path = sys.argv[1]
    
    if not os.path.isdir(folder_path):
        print(f"âŒ æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {folder_path}")
        sys.exit(1)
    
    # æŸ¥æ‰¾å›¾ç‰‡æ–‡ä»¶
    image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp'}
    image_files = []
    
    for file_path in Path(folder_path).iterdir():
        if file_path.is_file() and file_path.suffix.lower() in image_extensions:
            image_files.append(str(file_path))
    
    if not image_files:
        print(f"âŒ åœ¨ {folder_path} ä¸­æœªæ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶")
        sys.exit(1)
    
    print(f"ğŸ” åˆ†æ {len(image_files)} å¼ å›¾ç‰‡çš„tokenæ¶ˆè€—...")
    print("=" * 80)
    
    results = []
    total_original_tokens = 0
    
    for image_path in image_files:
        result = analyze_image(image_path)
        results.append(result)
        
        if result['success']:
            filename = os.path.basename(image_path)
            tokens = result['original_tokens']
            dimensions = result['original_dimensions']
            file_size = result['file_size_kb']
            
            print(f"ğŸ“· {filename}")
            print(f"   å°ºå¯¸: {dimensions} | å¤§å°: {file_size:.1f}KB | Token: {tokens}")
            
            total_original_tokens += tokens
            
            # æ˜¾ç¤ºæœ€ä½³å‹ç¼©é€‰é¡¹
            best_scenario = min(result['compressed_scenarios'], 
                              key=lambda x: x['tokens'])
            if best_scenario['token_savings'] > 0:
                savings_percent = (best_scenario['token_savings'] / tokens) * 100
                print(f"   ğŸ’¡ æ¨èå‹ç¼©åˆ° {best_scenario['max_size']}px: "
                      f"{best_scenario['tokens']} tokens (-{savings_percent:.1f}%)")
            else:
                print(f"   âœ… å½“å‰å°ºå¯¸å·²æœ€ä¼˜")
            print()
    
    # æ€»ç»“ç»Ÿè®¡
    successful_results = [r for r in results if r['success']]
    print("=" * 80)
    print("ğŸ“Š ç»Ÿè®¡æ‘˜è¦:")
    print(f"   å¤„ç†æˆåŠŸ: {len(successful_results)}/{len(results)} å¼ å›¾ç‰‡")
    print(f"   åŸå§‹æ€»tokenæ¶ˆè€—: {total_original_tokens:,}")
    
    if successful_results:
        # è®¡ç®—ä¸åŒå‹ç¼©è®¾ç½®çš„æ€»èŠ‚çœ
        for max_size in [512, 768, 1024, 1280]:
            total_compressed = sum(
                min(scenario['tokens'] for scenario in r['compressed_scenarios'] 
                    if scenario['max_size'] == max_size)
                for r in successful_results
            )
            savings = total_original_tokens - total_compressed
            savings_percent = (savings / total_original_tokens) * 100 if total_original_tokens > 0 else 0
            
            print(f"   å‹ç¼©åˆ° {max_size}px: {total_compressed:,} tokens "
                  f"(èŠ‚çœ {savings:,} tokens, {savings_percent:.1f}%)")
    
    # ç”Ÿæˆå»ºè®®
    print("\nğŸ’¡ ä¼˜åŒ–å»ºè®®:")
    large_images = [r for r in successful_results if r['original_tokens'] > 1000]
    if large_images:
        print(f"   â€¢ æœ‰ {len(large_images)} å¼ é«˜tokenæ¶ˆè€—å›¾ç‰‡ (>1000 tokens)")
        print("   â€¢ å»ºè®®ä½¿ç”¨ --compress --max-size 1024 æ¥å‡å°‘tokenæ¶ˆè€—")
    else:
        print("   â€¢ æ‰€æœ‰å›¾ç‰‡çš„tokenæ¶ˆè€—éƒ½æ¯”è¾ƒåˆç†")
    
    print(f"   â€¢ é¢„ä¼°æ‰¹é‡å¤„ç†æˆæœ¬: ~{total_original_tokens * 0.00001:.4f} USD (å‡è®¾$0.01/1K tokens)")
    
    # ä¿å­˜è¯¦ç»†åˆ†æç»“æœ
    output_file = "token_analysis.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    print(f"\nğŸ“ è¯¦ç»†åˆ†æç»“æœå·²ä¿å­˜åˆ°: {output_file}")


if __name__ == "__main__":
    main()